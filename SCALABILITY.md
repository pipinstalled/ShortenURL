### 1) جدا کردن پردازش‌های سنگین

به نظرم بهترین کار میتونه این باشه که اون بخش پردازش سنگین رو از کار اصلی API جدا بکنیم  
و برای این پردازش سنگین از یکی از message broker ها مثه RabbitMQ استفاده بکنیم.

---

### 2) آماده‌سازی برای multi-instance

باید چک بکنیم که تمام مواردی که مربوط به state هستن رو جدا بکنیم.  
مثلا فایل‌ها برن روی یک storage مشترک مثل MinIO  
و cache ها هم باید روی Redis ذخیره بشن.  
این‌جوری instance ها از هم مستقل هستن.

---

### 3) مدیریت ترافیک سنگین

اول از همه به نظرم باید چک کرد که حدوداً چند یوزر ممکنه اضافه بشن بعد از اون تبلیغات مثلاً.  
بعد از اون کاری که میشه کرد اینه که چک بکنیم با ابزارهای متریک که کدوم بخش‌ها ممکنه توی فشار بالا درست کار نکنن.  
بعد از اون روی همون موردها load test گذاشت تا بفهمیم چقدر تحمل ترافیک سنگین‌تر رو داره. 
و براساس اینکه چه تعداد یوزر قراره اضافه بشه اگه نیاز بود باز هم کاری کرد روی endpointها میشه موارد پایین رو هم انجام داد: 

- افزایش connection pool دیتابیس  
- استفاده از rate limiting برای کنترل ورودی‌های زیاد  
- ساختن instance های بیشتر (scaling)  
- استفاده از مواردی مثل RabbitMQ برای اینکه پردازش‌های سنگین رو از بعضی endpoint ها جدا بکنیم  
